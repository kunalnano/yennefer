<!-- Animated Header -->
<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12,19,20,24&height=230&section=header&text=âš¡%20Yennefer&fontSize=70&fontColor=ffffff&animation=twinkling&fontAlignY=35&desc=Local%20AI%20with%20attitude&descSize=20&descAlignY=55" />

<div align="center">

<!-- Typing Animation -->
<a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=600&size=22&pause=1000&color=A855F7&center=true&vCenter=true&multiline=true&repeat=true&width=600&height=100&lines=%22Magic+is+chaos%2C+art%2C+and+science.%22;No+cloud.+No+compromises.+No+coddling.;She+thinks+before+speaking%E2%80%94;but+keeps+her+thoughts+to+herself." alt="Typing SVG" /></a>

<br><br>

<!-- Fancy Badges -->
<a href="https://python.org"><img src="https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white&labelColor=1e1e2e" /></a>
<a href="https://lmstudio.ai"><img src="https://img.shields.io/badge/LM%20Studio-Local%20LLM-00D084?style=for-the-badge&logo=ai&logoColor=white&labelColor=1e1e2e" /></a>
<a href="https://elevenlabs.io"><img src="https://img.shields.io/badge/ElevenLabs-Neural%20Voice-A855F7?style=for-the-badge&logo=audacity&logoColor=white&labelColor=1e1e2e" /></a>
<img src="https://img.shields.io/badge/Platform-Windows%20%7C%20Mac-6366F1?style=for-the-badge&logo=windows&logoColor=white&labelColor=1e1e2e" />
<a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-F97316?style=for-the-badge&logo=opensourceinitiative&logoColor=white&labelColor=1e1e2e" /></a>

<br><br>

<!-- Quick Links with Icons -->
[<img src="https://img.shields.io/badge/âš¡_Features-A855F7?style=flat-square" />](#-features)
[<img src="https://img.shields.io/badge/ğŸš€_Quick_Start-6366F1?style=flat-square" />](#-quick-start)
[<img src="https://img.shields.io/badge/ğŸ¤–_Models-00D084?style=flat-square" />](#-recommended-models)
[<img src="https://img.shields.io/badge/ğŸ™ï¸_Voice_Config-F97316?style=flat-square" />](#%EF%B8%8F-voice-configuration)
[<img src="https://img.shields.io/badge/ğŸ“‹_Roadmap-EC4899?style=flat-square" />](#-roadmap)

</div>

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ­ What Is This?

Yennefer is a conversational AI that runs **entirely on your machine** using [LM Studio](https://lmstudio.ai). She's not another sycophantic assistantâ€”she has opinions, standards, and won't coddle you.

The only cloud touch is [ElevenLabs](https://elevenlabs.io) for premium neural TTS (optionalâ€”free tier gives you 10K chars/month).

<br>

### Why Local?

> ğŸ”’ Your conversations **never leave your hardware**
> 
> ğŸ’° No API rate limits or surprise bills
> 
> ğŸ”„ Swap models anytimeâ€”Nemotron, Qwen, Llama, whatever
> 
> âœˆï¸ Works offline (except voice synthesis)

### Why Yennefer?

> ğŸ¯ Direct feedback, not corporate pleasantries
> 
> ğŸ§  Actually helpful, not just agreeable
> 
> ğŸ™ï¸ Premium voice that doesn't sound like a robot
> 
> âš¡ Fastâ€”runs on your GPU, not a queue

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ—ï¸ Architecture

<div align="center">

```mermaid
flowchart LR
    subgraph LOCAL ["  ğŸ’» YOUR MACHINE  "]
        direction LR
        A[" ğŸ‘¤ You "] -->|"âŒ¨ï¸ Input"| B[" âš¡ Yennefer\nOrchestrator "]
        B -->|"ğŸ’­ Query"| C[" ğŸ§  LM Studio\nLocal LLM "]
        C -->|"ğŸ’¬ Response"| B
    end
    
    B -->|"ğŸ”Š TTS Request"| D[" â˜ï¸ ElevenLabs\nVoice API "]
    D -->|"ğŸ™ï¸ Audio"| B
    B -->|"ğŸ”ˆ Speech"| A

    style LOCAL fill:#1e1e2e,stroke:#a855f7,stroke-width:2px,color:#ffffff
    style A fill:#6366f1,stroke:#818cf8,color:#ffffff
    style B fill:#a855f7,stroke:#c084fc,color:#ffffff
    style C fill:#00d084,stroke:#34d399,color:#1e1e2e
    style D fill:#f97316,stroke:#fb923c,color:#ffffff
```

<br>

<table>
<tr>
<td align="center">
<img src="https://img.shields.io/badge/You-6366F1?style=flat-square&logo=user&logoColor=white" /><br>
<sub>Text or Voice Input</sub>
</td>
<td align="center">
â¡ï¸
</td>
<td align="center">
<img src="https://img.shields.io/badge/Yennefer-A855F7?style=flat-square&logo=bot&logoColor=white" /><br>
<sub>Orchestrator</sub>
</td>
<td align="center">
â¡ï¸
</td>
<td align="center">
<img src="https://img.shields.io/badge/LM_Studio-00D084?style=flat-square&logo=ai&logoColor=white" /><br>
<sub>Local LLM</sub>
</td>
</tr>
</table>

<br>

<img src="https://img.shields.io/badge/â†“_Only_External_Call_â†“-1e1e2e?style=flat-square" />

<br>

<img src="https://img.shields.io/badge/ElevenLabs-F97316?style=for-the-badge&logo=audacity&logoColor=white" />
<br>
<sub>ğŸŒ Cloud TTS â€¢ Optional â€¢ Free Tier Available</sub>

</div>

<br>

<details>
<summary><b>ğŸ“œ View Text Diagram</b></summary>
<br>

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸ’»  YOUR MACHINE                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ğŸ‘¤ You   â”‚â”€â”€â”€â–¶â”‚  âš¡ Yennefer    â”‚â”€â”€â”€â–¶â”‚  ğŸ§  LM Studio      â”‚  â”‚
â”‚  â”‚ keyboard â”‚    â”‚  orchestrator  â”‚    â”‚  local LLM engine  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ â˜ï¸ ElevenLabs  â”‚  â† Only external call
                â”‚   voice API    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</details>

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## âœ¨ Features

<div align="center">

| | Feature | Description |
|:--:|:--------|:------------|
| ğŸ§  | **Local LLM** | Any GGUF model via LM Studioâ€”Nemotron, Qwen, Llama, Mistral, DeepSeek |
| ğŸ™ï¸ | **Premium Voice** | ElevenLabs neural TTS with custom voice cloning support |
| ğŸ­ | **Real Personality** | Sharp, confident, wittyâ€”inspired by Yennefer of Vengerberg |
| ğŸ“Š | **Token Tracking** | Visual context window with auto-trim at 85% capacity |
| ğŸ’³ | **Credits Monitor** | Real-time ElevenLabs character usage tracking |
| ğŸ§¹ | **Thinking Stripper** | Auto-removes `<think>` tags so reasoning isn't spoken aloud |
| ğŸ–¥ï¸ | **Cross-Platform** | Windows native or Mac â†’ Windows remote via LAN |

</div>

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸš€ Quick Start

### Prerequisites

<div align="center">

| Requirement | Why | Get It |
|:-----------:|:---:|:------:|
| <img src="https://skillicons.dev/icons?i=python" width="40"><br>**Python 3.10+** | Runtime | [python.org](https://python.org) |
| <img src="https://img.icons8.com/fluency/48/artificial-intelligence.png" width="40"><br>**LM Studio** | Local LLM | [lmstudio.ai](https://lmstudio.ai) |
| <img src="https://img.icons8.com/color/48/voice-id.png" width="40"><br>**ElevenLabs** | Voice | [elevenlabs.io](https://elevenlabs.io) |
| <img src="https://skillicons.dev/icons?i=nvidia" width="40"><br>**NVIDIA GPU** | Speed | Recommended |

</div>

### Installation

```bash
# Clone the repo
git clone https://github.com/kunalnano/yennefer.git
cd yennefer

# Windows
.\setup.bat

# Mac/Linux
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

### Configuration

```bash
# Create your environment file
cp .env.example .env
```

Edit `.env` with your keys:
```env
ELEVENLABS_API_KEY=your_key_here      # From elevenlabs.io/settings/api-keys
ELEVENLABS_VOICE_ID=your_voice_id     # From your Voice Library
```

### Launch

<table>
<tr>
<td>

**1ï¸âƒ£ Start LM Studio**
- Load a model
- Go to Local Server
- Click Start

</td>
<td>

**2ï¸âƒ£ Run Yennefer**
```bash
# Windows
.\start_yennefer.bat

# Mac/Linux
./start_yennefer.sh
```

</td>
</tr>
</table>

**That's it. She's waiting.**

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ® Commands

<div align="center">

| Command | What It Does |
|:-------:|:-------------|
| `status` | ğŸ“Š Show token usage and context window health |
| `credits` | ğŸ’³ Display ElevenLabs character usage |
| `voice` | ğŸ™ï¸ Show voice settings and session stats |
| `clear` | ğŸ§¹ Wipe conversation memory |
| `quit` | ğŸ‘‹ Exit gracefully |

</div>

> ğŸ’¡ **Pro tip:** On Windows, press `Win+H` for system-level voice dictation.

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ¤– Recommended Models

<div align="center">

| Model | VRAM | Speed | Notes |
|:------|:----:|:-----:|:------|
| **NVIDIA Nemotron-Mini-4B** | ~4GB | âš¡âš¡âš¡ | Great for quick interactions |
| **Nemotron-3-Nano-30B-A3B** | ~18GB | âš¡âš¡ | Best reasoning-to-VRAM ratio |
| **Qwen3-30B-A3B** | ~18GB | âš¡âš¡ | Excellent all-around performer |
| **Llama-3.1-8B-Instruct** | ~6GB | âš¡âš¡âš¡ | Good for lighter hardware |
| **DeepSeek-R1-Distill-Qwen-14B** | ~10GB | âš¡âš¡ | Strong reasoning model |

</div>

> ğŸ§  **Reasoning models** that use `<think>...</think>` tags are automatically filtered. Yennefer thinks before speaking, but keeps her thoughts to herself.

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ™ï¸ Voice Configuration

<div align="center">

| Model | Latency | Quality | Best For |
|:------|:-------:|:-------:|:---------|
| `eleven_turbo_v2_5` | âš¡ Fastest | Good | Daily use |
| `eleven_flash_v2_5` | Fast | Good | Balance |
| `eleven_multilingual_v2` | Slower | Best | Quality priority |

</div>

Fine-tune the voice in `config/jarvis.yaml`:

```yaml
voice_output:
  stability: 0.6          # 0-1: Higher = more consistent pitch
  similarity_boost: 0.75  # 0-1: Voice matching accuracy
  style: 0.0              # 0-1: Style exaggeration (keep low)
  speed: 1.15             # 0.25-4.0: Speech rate
```

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸŒ Remote Setup (Mac â†’ Windows)

Running LM Studio on a beefy Windows rig but want to talk from your Mac?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ Mac         â”‚    LAN/WiFi        â”‚  ğŸªŸ Windows     â”‚
â”‚  (thin client)  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (GPU server)   â”‚
â”‚  Yennefer CLI   â”‚                    â”‚  LM Studio      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Windows (LM Studio):** Enable "Serve on Local Network" in Local Server settings
2. **Windows:** Run `ipconfig` â†’ note your LAN IP (e.g., `192.168.1.100`)
3. **Mac:** Update `config/jarvis.yaml`:
   ```yaml
   llm:
     api_base: "http://192.168.1.100:1234/v1"
   ```

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ­ Personality

<div align="center">

*Yennefer doesn't do corporate AI pleasantries. She's helpful, but she'll call out bad ideas.*

</div>

<table>
<tr>
<td width="33%">

> **You:** I'm thinking of learning three programming languages at once.
>
> **Yennefer:** How ambitious. You'll drown in syntax before you master any of them. Pick one. Learn it properly. Then consider the others.

</td>
<td width="33%">

> **You:** Can you help me with my code?
>
> **Yennefer:** Show me what you've got. I'll tell you what's wrong with it.

</td>
<td width="33%">

> **You:** I want to build a startup but I have no idea what problem to solve.
>
> **Yennefer:** Then you don't want to build a startupâ€”you want the *idea* of building one. Find a problem that genuinely irritates you first.

</td>
</tr>
</table>

<div align="center">

*She's an equal, not a servant. Inspired by Yennefer of Vengerbergâ€”confident, sharp, doesn't suffer fools gladly.*

</div>

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ—‚ï¸ Project Structure

```
yennefer/
â”œâ”€â”€ jarvis/                 # Core Python package
â”‚   â”œâ”€â”€ main.py             # Entry point + ASCII banner
â”‚   â”œâ”€â”€ orchestrator.py     # Conversation loop controller
â”‚   â”œâ”€â”€ brain.py            # LLM integration (OpenAI-compatible API)
â”‚   â”œâ”€â”€ voice.py            # ElevenLabs TTS + thinking tag stripper
â”‚   â”œâ”€â”€ ears.py             # Input handler
â”‚   â””â”€â”€ config.py           # YAML loader with ${ENV_VAR} expansion
â”œâ”€â”€ config/
â”‚   â””â”€â”€ jarvis.yaml         # Main configuration file
â”œâ”€â”€ .env.example            # API key template
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ start_yennefer.bat      # Windows launcher
â”œâ”€â”€ start_yennefer.sh       # Mac/Linux launcher
â”œâ”€â”€ CHANGELOG.md            # Version history
â””â”€â”€ README.md               # You are here
```

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ› Troubleshooting

<details>
<summary><b>ğŸ”´ "Cannot connect to LM Studio"</b></summary>
<br>

- Is LM Studio running with a model loaded?
- Check Local Server tab shows "Running"
- Verify `api_base` in config matches your setup (default: `http://localhost:1234/v1`)

</details>

<details>
<summary><b>ğŸ”´ "ElevenLabs 401 error"</b></summary>
<br>

- Verify API key in `.env` file
- Check key validity at https://elevenlabs.io/app/settings/api-keys
- Ensure you haven't exceeded your character limit

</details>

<details>
<summary><b>ğŸ”´ Voice sounds robotic or jarring</b></summary>
<br>

- Increase `stability` to 0.7-0.8 in config
- Try `eleven_multilingual_v2` model for smoother output
- Reduce `speed` if words are clipping

</details>

<details>
<summary><b>ğŸ”´ Thinking tags being spoken aloud</b></summary>
<br>

- Update to v0.3.0+ (automatic stripping included)
- The stripper handles `<think>`, `<thinking>`, unclosed tags, and edge cases

</details>

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ“‹ Roadmap

<div align="center">

### ğŸ”œ Coming Soon

| Feature | Status |
|:--------|:------:|
| Wake word detection â€” "Hey Yennefer" | ğŸ”² |
| Streaming TTS â€” speak before generation completes | ğŸ”² |
| Interrupt handling â€” stop mid-sentence | ğŸ”² |

### ğŸ”® Future

| Feature | Status |
|:--------|:------:|
| Memory persistence across sessions | ğŸ”² |
| Multi-voice support â€” switch characters | ğŸ”² |
| Tool plugins â€” file ops, web search, etc. | ğŸ”² |

</div>

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

## ğŸ“œ License

<div align="center">

MIT â€” Do whatever you want. Credit appreciated but not required.

</div>

## ğŸ¤ Contributing

PRs welcome. See [CHANGELOG.md](CHANGELOG.md) for what's been done.

<div align="center">

| Good First Contributions |
|:------------------------|
| ğŸ¤ Wake word detection integration (Porcupine, Snowboy, etc.) |
| ğŸ”Š Alternative TTS backends (Coqui, Bark, local options) |
| ğŸ™ï¸ Voice activity detection for natural turn-taking |
| ğŸ”¢ Tiktoken integration for accurate token counting |

</div>

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif">

<div align="center">

<br>

### Built with spite and good taste.

<br>

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12,19,20,24&height=100&section=footer"/>

<br>

**If you find this useful, star the repo.**

*Yennefer doesn't ask for validation, but the algorithm appreciates it.*

<br>

![GitHub stars](https://img.shields.io/github/stars/kunalnano/yennefer?style=social)

</div>
